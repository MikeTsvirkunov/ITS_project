{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from json import load\n",
    "from spacy.util import minibatch, compounding\n",
    "import spacy\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from spacy.matcher import PhraseMatcher\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, RocCurveDisplay, auc, mean_squared_error\n",
    "from sklearn.preprocessing import normalize\n",
    "import re\n",
    "from spacy.training.example import Example\n",
    "nlp = spacy.load(\"ru_core_news_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../Data/Events/type_of_events.json', 'r', encoding='utf-8') as js:\n",
    "    discription_of_event = load(js)\n",
    "ner = nlp.get_pipe(\"ner\")\n",
    "punctuation = list(map(lambda a: a, punctuation)) + \\\n",
    "    ['(', ')', '\"', '«', '»', \"'\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_describer(text, ent):\n",
    "    return (text, {\"entities\": ent})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 5, 10, 15]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m.start() for m in re.finditer('test', 'test test test test')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = []\n",
    "for events in discription_of_event:\n",
    "    description = discription_of_event[events][\"описание\"]\n",
    "    new_skills = discription_of_event[events][\"new_skills\"]\n",
    "    for skill in new_skills:\n",
    "        TRAIN_DATA.append(to_describer(description, [(position.start(), position.end(), \"type\") for position in re.finditer(skill, description)]))\n",
    "        # print([(m.start(), m.end()) for m in re.finditer(skill, description)])\n",
    "        # x = i.find(j)\n",
    "# TRAIN_DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, annotations in TRAIN_DATA:\n",
    "  for ent in annotations.get(\"entities\"):\n",
    "    ner.add_label(ent[2])\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "unaffected_pipes = [\n",
    "    pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "\n",
    "# shuffle(TRAIN_DATA)\n",
    "\n",
    "losses = {}\n",
    "for batch in spacy.util.minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001)):\n",
    "    for text, annotations in batch:\n",
    "        doc = nlp.make_doc(text)\n",
    "        example = Example.from_dict(doc, annotations)\n",
    "        nlp.update([example], losses=losses, drop=0.3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITS_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
