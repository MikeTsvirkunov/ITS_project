{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mike\\Desktop\\ITS_project\\ITS_project\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, RocCurveDisplay, auc, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from json import load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_discriptors = list()\n",
    "with open('../../Data/Words/word_pairs_not_disc.txt', 'r', encoding='utf-8') as txt:\n",
    "    for i in txt:\n",
    "        not_discriptors.append(i.replace('\\n', ''))\n",
    "\n",
    "with open('../../Data/Events/type_of_events.json', 'r', encoding='utf-8') as js:\n",
    "    events = load(js)\n",
    "\n",
    "with open('../../Data/Datasets/data.json', 'r', encoding='utf-8') as js:\n",
    "    discriptors = load(js)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_disc = {'expession': [], 'is_discr': []}\n",
    "for subject in discriptors.values():\n",
    "    for d in sum(subject.values(), []):\n",
    "        dict_of_disc['expession'].append(d)\n",
    "        dict_of_disc['is_discr'].append(True)\n",
    "\n",
    "for subject in not_discriptors:\n",
    "    dict_of_disc['expession'].append(subject)\n",
    "    dict_of_disc['is_discr'].append(False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expession</th>\n",
       "      <th>is_discr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>основные положения теории истории</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>основные положения методологии истории</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>место истории в системе гуманитарного знания</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>закономерности исторического процесса</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>этапы исторического процесса</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>международные обмены</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>международных стажировок</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>темпа жизни</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>увеличение потока</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>найти путь</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1065 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         expession  is_discr\n",
       "0                основные положения теории истории      True\n",
       "1           основные положения методологии истории      True\n",
       "2     место истории в системе гуманитарного знания      True\n",
       "3            закономерности исторического процесса      True\n",
       "4                     этапы исторического процесса      True\n",
       "...                                            ...       ...\n",
       "1060                          международные обмены     False\n",
       "1061                      международных стажировок     False\n",
       "1062                                   темпа жизни     False\n",
       "1063                             увеличение потока     False\n",
       "1064                                    найти путь     False\n",
       "\n",
       "[1065 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dict_of_disc)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# model_class, tokenizer_class, pretrained_weights = (\n",
    "#     ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "# Хотите BERT вместо distilBERT? Раскомментируйте следующую строку:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Загрузка предобученной модели/токенизатора\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = df['expession'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "padded = [tokenizer.encode(i, add_special_tokens=True) for i in df['expession'].to_list()]\n",
    "ml = len(max(padded, key=len))\n",
    "for i in padded:\n",
    "    for _ in range(ml-len(i)):\n",
    "        i.append(0)\n",
    "\n",
    "padded = np.array(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(padded)\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    last_hidden_states = model(input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = last_hidden_states[0][:,0,:].numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['is_discr']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, random_state=71)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (Dense)               (None, 1152)              885888    \n",
      "                                                                 \n",
      " hidden_layer_2 (Dense)      (None, 1536)              1771008   \n",
      "                                                                 \n",
      " hidden_layer_3 (Dense)      (None, 1152)              1770624   \n",
      "                                                                 \n",
      " hidden_layer_4 (Dense)      (None, 384)               442752    \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 385       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,870,657\n",
      "Trainable params: 4,870,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model_class = tf.keras.models.Sequential()\n",
    "model_class.add(tf.keras.layers.Dense(int(X_train[0].shape[0]*1.5), activation='softmax',\n",
    "                                      input_shape=(X_train[0].shape[0],), name='input'))\n",
    "model_class.add(tf.keras.layers.Dense(\n",
    "    int(X_train[0].shape[0]*2), activation='relu', name='hidden_layer_2'))\n",
    "model_class.add(tf.keras.layers.Dense(\n",
    "    int(X_train[0].shape[0]*1.5), activation='relu', name='hidden_layer_3'))\n",
    "model_class.add(tf.keras.layers.Dense(\n",
    "    int(X_train[0].shape[0]*0.5), activation='relu', name='hidden_layer_4'))\n",
    "model_class.add(tf.keras.layers.Dense(1, name='output', activation='sigmoid'))\n",
    "model_class.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class.compile(\n",
    "    loss=tf.keras.metrics.binary_crossentropy, #  'mse',  # Функция потерь\n",
    "    optimizer='Adam',  # Оптимизатор\n",
    "    metrics=[  # Метрики\n",
    "        'mse', \n",
    "        # tf.keras.metrics.Precision()\n",
    "        # tf.keras.metrics.FalsePositives\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "239/239 [==============================] - 9s 39ms/step - loss: 0.4242 - mse: 0.1346 - val_loss: 0.5822 - val_mse: 0.1595\n",
      "Epoch 2/10\n",
      "239/239 [==============================] - 9s 39ms/step - loss: 0.4122 - mse: 0.1282 - val_loss: 0.5778 - val_mse: 0.1705\n",
      "Epoch 3/10\n",
      "239/239 [==============================] - 9s 39ms/step - loss: 0.4870 - mse: 0.1532 - val_loss: 0.5609 - val_mse: 0.1782\n",
      "Epoch 4/10\n",
      "239/239 [==============================] - 9s 39ms/step - loss: 0.4407 - mse: 0.1391 - val_loss: 0.5111 - val_mse: 0.1549\n",
      "Epoch 5/10\n",
      "239/239 [==============================] - 9s 39ms/step - loss: 0.4533 - mse: 0.1425 - val_loss: 0.5478 - val_mse: 0.1844\n",
      "Epoch 6/10\n",
      "239/239 [==============================] - 9s 39ms/step - loss: 0.4386 - mse: 0.1398 - val_loss: 0.5622 - val_mse: 0.1528\n",
      "Epoch 7/10\n",
      "239/239 [==============================] - 9s 39ms/step - loss: 0.4300 - mse: 0.1355 - val_loss: 0.5491 - val_mse: 0.1581\n",
      "Epoch 8/10\n",
      "239/239 [==============================] - 9s 39ms/step - loss: 0.4460 - mse: 0.1418 - val_loss: 0.5778 - val_mse: 0.1737\n",
      "Epoch 9/10\n",
      "239/239 [==============================] - 9s 39ms/step - loss: 0.4360 - mse: 0.1351 - val_loss: 0.6095 - val_mse: 0.1892\n",
      "Epoch 10/10\n",
      "239/239 [==============================] - 9s 39ms/step - loss: 0.4331 - mse: 0.1374 - val_loss: 0.5230 - val_mse: 0.1562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ba1cfd02b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class.fit(\n",
    "    X_train,  # Набор входных данных\n",
    "    y_train.to_numpy().astype(int),  # Набор правильных ответов\n",
    "    validation_split=0.4,  # Этот параметр автоматически выделит часть обучающего набора на валидационные данные. В данном случа 20%\n",
    "    epochs=10,  # Процесс обучения завершится после 10 эпох\n",
    "    # Набор данных будет разбит на пакеты (батчи) по 8 элементов набора в каждом.\n",
    "    batch_size=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "predict = model_class.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15022235"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(predict, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 7ms/step\n",
      "Accuracy\n",
      "0.815962441314554\n",
      "Confusion matrix\n",
      "[[221 137]\n",
      " [ 59 648]]\n",
      "Precision, Recall, F\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.79      0.62      0.69       358\n",
      "        True       0.83      0.92      0.87       707\n",
      "\n",
      "    accuracy                           0.82      1065\n",
      "   macro avg       0.81      0.77      0.78      1065\n",
      "weighted avg       0.81      0.82      0.81      1065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = 0.65\n",
    "predictA = model_class.predict(features)\n",
    "print('Accuracy')\n",
    "print(accuracy_score(labels, predictA > t))\n",
    "print('Confusion matrix')\n",
    "print(confusion_matrix(labels, predictA > t))\n",
    "print('Precision, Recall, F\\n', classification_report(\n",
    "    labels, predictA > t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.append(X_train, X_test, axis=0)\n",
    "rr = np.append(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "0.7827715355805244\n",
      "Confusion matrix\n",
      "[[ 43  53]\n",
      " [  5 166]]\n",
      "Precision, Recall, F\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.45      0.60        96\n",
      "        True       0.76      0.97      0.85       171\n",
      "\n",
      "    accuracy                           0.78       267\n",
      "   macro avg       0.83      0.71      0.72       267\n",
      "weighted avg       0.81      0.78      0.76       267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy')\n",
    "print(accuracy_score(rr, r > 0.5))\n",
    "print('Confusion matrix')\n",
    "print(confusion_matrix(rr, r > 0.5))\n",
    "print('Precision, Recall, F\\n', classification_report(\n",
    "    rr, r > 0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../PipeLines/Classifications/checker_is_discriptor\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../PipeLines/Classifications/checker_is_discriptor\\assets\n"
     ]
    }
   ],
   "source": [
    "# model_class.save('../../PipeLines/Classifications/checker_is_discriptor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nlp_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "451f605c58fa7f82d1d484da5a7eef3d214b63567dc0911e0bf409faa3ae9cbb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
