{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mike\\Desktop\\ITS_project\\ITS_project\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, RocCurveDisplay, auc, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from json import load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_discriptors = list()\n",
    "with open('../../Data/Words/word_pairs_not_disc.txt', 'r', encoding='utf-8') as txt:\n",
    "    for i in txt:\n",
    "        not_discriptors.append(i.replace('\\n', ''))\n",
    "\n",
    "with open('../../Data/Events/type_of_events.json', 'r', encoding='utf-8') as js:\n",
    "    events = load(js)\n",
    "\n",
    "with open('../../Data/Datasets/data.json', 'r', encoding='utf-8') as js:\n",
    "    discriptors = load(js)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_disc = {'expession': [], 'is_discr': []}\n",
    "for subject in discriptors.values():\n",
    "    for d in sum(subject.values(), []):\n",
    "        dict_of_disc['expession'].append(d)\n",
    "        dict_of_disc['is_discr'].append(True)\n",
    "\n",
    "for subject in not_discriptors:\n",
    "    dict_of_disc['expession'].append(subject)\n",
    "    dict_of_disc['is_discr'].append(False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expession</th>\n",
       "      <th>is_discr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>основные положения теории истории</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>основные положения методологии истории</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>место истории в системе гуманитарного знания</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>закономерности исторического процесса</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>этапы исторического процесса</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>Дать практические простые инструменты или рути...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>Эмбодимент (embodiment)– переводится как вопло...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>То есть это выражение качеств, в том числе лид...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>Римская пословица Mens sana in corpore sano(В ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>То есть наш настрой, настроение, состояние, в ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1056 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              expession  is_discr\n",
       "0                     основные положения теории истории      True\n",
       "1                основные положения методологии истории      True\n",
       "2          место истории в системе гуманитарного знания      True\n",
       "3                 закономерности исторического процесса      True\n",
       "4                          этапы исторического процесса      True\n",
       "...                                                 ...       ...\n",
       "1051  Дать практические простые инструменты или рути...     False\n",
       "1052  Эмбодимент (embodiment)– переводится как вопло...     False\n",
       "1053  То есть это выражение качеств, в том числе лид...     False\n",
       "1054  Римская пословица Mens sana in corpore sano(В ...     False\n",
       "1055  То есть наш настрой, настроение, состояние, в ...     False\n",
       "\n",
       "[1056 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dict_of_disc)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# model_class, tokenizer_class, pretrained_weights = (\n",
    "#     ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "# Хотите BERT вместо distilBERT? Раскомментируйте следующую строку:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Загрузка предобученной модели/токенизатора\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = df['expession'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "padded = [tokenizer.encode(i, add_special_tokens=True) for i in df['expession'].to_list()]\n",
    "ml = len(max(padded, key=len))\n",
    "for i in padded:\n",
    "    for _ in range(ml-len(i)):\n",
    "        i.append(0)\n",
    "\n",
    "padded = np.array(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(padded)\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    last_hidden_states = model(input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = last_hidden_states[0][:,0,:].numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['is_discr']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, random_state=71)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (Dense)               (None, 1152)              885888    \n",
      "                                                                 \n",
      " hidden_layer_2 (Dense)      (None, 1536)              1771008   \n",
      "                                                                 \n",
      " hidden_layer_3 (Dense)      (None, 1152)              1770624   \n",
      "                                                                 \n",
      " hidden_layer_4 (Dense)      (None, 384)               442752    \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 385       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,870,657\n",
      "Trainable params: 4,870,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model_class = tf.keras.models.Sequential()\n",
    "model_class.add(tf.keras.layers.Dense(int(X_train[0].shape[0]*1.5), activation='softmax',\n",
    "                                      input_shape=(X_train[0].shape[0],), name='input'))\n",
    "model_class.add(tf.keras.layers.Dense(\n",
    "    int(X_train[0].shape[0]*2), activation='relu', name='hidden_layer_2'))\n",
    "model_class.add(tf.keras.layers.Dense(\n",
    "    int(X_train[0].shape[0]*1.5), activation='relu', name='hidden_layer_3'))\n",
    "model_class.add(tf.keras.layers.Dense(\n",
    "    int(X_train[0].shape[0]*0.5), activation='relu', name='hidden_layer_4'))\n",
    "model_class.add(tf.keras.layers.Dense(1, name='output'))\n",
    "model_class.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class.compile(\n",
    "    loss='mse',  # Функция потерь\n",
    "    optimizer='Adam',  # Оптимизатор\n",
    "    metrics=[  # Метрики\n",
    "        'mse',  # Если у объекта назначено имя, то можно вызвать объект с его помощью\n",
    "        # tf.keras.metrics.Precision()\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.2524 - mse: 0.2524 - val_loss: 0.3141 - val_mse: 0.3141\n",
      "Epoch 2/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2229 - mse: 0.2229 - val_loss: 0.2305 - val_mse: 0.2305\n",
      "Epoch 3/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2022 - mse: 0.2022 - val_loss: 0.1992 - val_mse: 0.1992\n",
      "Epoch 4/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1724 - mse: 0.1724 - val_loss: 0.1699 - val_mse: 0.1699\n",
      "Epoch 5/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2229 - mse: 0.2229 - val_loss: 0.2323 - val_mse: 0.2323\n",
      "Epoch 6/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2149 - mse: 0.2149 - val_loss: 0.2275 - val_mse: 0.2275\n",
      "Epoch 7/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2151 - mse: 0.2151 - val_loss: 0.2320 - val_mse: 0.2320\n",
      "Epoch 8/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2127 - mse: 0.2127 - val_loss: 0.2296 - val_mse: 0.2296\n",
      "Epoch 9/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2147 - mse: 0.2147 - val_loss: 0.2129 - val_mse: 0.2129\n",
      "Epoch 10/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2090 - mse: 0.2090 - val_loss: 0.2246 - val_mse: 0.2246\n",
      "Epoch 11/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2141 - mse: 0.2141 - val_loss: 0.2237 - val_mse: 0.2237\n",
      "Epoch 12/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2148 - mse: 0.2148 - val_loss: 0.2341 - val_mse: 0.2341\n",
      "Epoch 13/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2153 - mse: 0.2153 - val_loss: 0.2237 - val_mse: 0.2237\n",
      "Epoch 14/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2164 - mse: 0.2164 - val_loss: 0.2236 - val_mse: 0.2236\n",
      "Epoch 15/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2159 - mse: 0.2159 - val_loss: 0.2328 - val_mse: 0.2328\n",
      "Epoch 16/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2144 - mse: 0.2144 - val_loss: 0.2237 - val_mse: 0.2237\n",
      "Epoch 17/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2144 - mse: 0.2144 - val_loss: 0.2294 - val_mse: 0.2294\n",
      "Epoch 18/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2145 - mse: 0.2145 - val_loss: 0.2293 - val_mse: 0.2293\n",
      "Epoch 19/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2148 - mse: 0.2148 - val_loss: 0.2243 - val_mse: 0.2243\n",
      "Epoch 20/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2149 - mse: 0.2149 - val_loss: 0.2341 - val_mse: 0.2341\n",
      "Epoch 21/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2142 - mse: 0.2142 - val_loss: 0.2236 - val_mse: 0.2236\n",
      "Epoch 22/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2135 - mse: 0.2135 - val_loss: 0.2334 - val_mse: 0.2334\n",
      "Epoch 23/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2142 - mse: 0.2142 - val_loss: 0.2281 - val_mse: 0.2281\n",
      "Epoch 24/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2152 - mse: 0.2152 - val_loss: 0.2253 - val_mse: 0.2253\n",
      "Epoch 25/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2141 - mse: 0.2141 - val_loss: 0.2237 - val_mse: 0.2237\n",
      "Epoch 26/40\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.2146 - mse: 0.2146 - val_loss: 0.2236 - val_mse: 0.2236\n",
      "Epoch 27/40\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2240 - val_mse: 0.2240\n",
      "Epoch 28/40\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.2164 - mse: 0.2164 - val_loss: 0.2236 - val_mse: 0.2236\n",
      "Epoch 29/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2145 - mse: 0.2145 - val_loss: 0.2280 - val_mse: 0.2280\n",
      "Epoch 30/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2134 - mse: 0.2134 - val_loss: 0.2246 - val_mse: 0.2246\n",
      "Epoch 31/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2148 - mse: 0.2148 - val_loss: 0.2282 - val_mse: 0.2282\n",
      "Epoch 32/40\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.2147 - mse: 0.2147 - val_loss: 0.2237 - val_mse: 0.2237\n",
      "Epoch 33/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2162 - mse: 0.2162 - val_loss: 0.2349 - val_mse: 0.2349\n",
      "Epoch 34/40\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.2147 - mse: 0.2147 - val_loss: 0.2240 - val_mse: 0.2240\n",
      "Epoch 35/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2144 - mse: 0.2144 - val_loss: 0.2251 - val_mse: 0.2251\n",
      "Epoch 36/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2168 - mse: 0.2168 - val_loss: 0.2246 - val_mse: 0.2246\n",
      "Epoch 37/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2135 - mse: 0.2135 - val_loss: 0.2359 - val_mse: 0.2359\n",
      "Epoch 38/40\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.2146 - mse: 0.2146 - val_loss: 0.2242 - val_mse: 0.2242\n",
      "Epoch 39/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2140 - mse: 0.2140 - val_loss: 0.2290 - val_mse: 0.2290\n",
      "Epoch 40/40\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2136 - mse: 0.2136 - val_loss: 0.2249 - val_mse: 0.2249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26447e6f370>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class.fit(\n",
    "    X_train,  # Набор входных данных\n",
    "    y_train.to_numpy().astype(int),  # Набор правильных ответов\n",
    "    validation_split=0.4,  # Этот параметр автоматически выделит часть обучающего набора на валидационные данные. В данном случа 20%\n",
    "    epochs=40,  # Процесс обучения завершится после 10 эпох\n",
    "    # Набор данных будет разбит на пакеты (батчи) по 8 элементов набора в каждом.\n",
    "    batch_size=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "predict = model_class.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15923554"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(predict, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 1ms/step\n",
      "Accuracy\n",
      "0.8106060606060606\n",
      "Confusion matrix\n",
      "[[157 192]\n",
      " [  8 699]]\n",
      "Precision, Recall, F\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.45      0.61       349\n",
      "        True       0.78      0.99      0.87       707\n",
      "\n",
      "    accuracy                           0.81      1056\n",
      "   macro avg       0.87      0.72      0.74      1056\n",
      "weighted avg       0.84      0.81      0.79      1056\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictA = model_class.predict(features)\n",
    "print('Accuracy')\n",
    "print(accuracy_score(labels, predictA > 0.5))\n",
    "print('Confusion matrix')\n",
    "print(confusion_matrix(labels, predictA > 0.5))\n",
    "print('Precision, Recall, F\\n', classification_report(\n",
    "    labels, predictA > 0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "0.7840909090909091\n",
      "Confusion matrix\n",
      "[[ 41  57]\n",
      " [  0 166]]\n",
      "Precision, Recall, F\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.42      0.59        98\n",
      "        True       0.74      1.00      0.85       166\n",
      "\n",
      "    accuracy                           0.78       264\n",
      "   macro avg       0.87      0.71      0.72       264\n",
      "weighted avg       0.84      0.78      0.76       264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy')\n",
    "print(accuracy_score(y_test, predict > 0.5))\n",
    "print('Confusion matrix')\n",
    "print(confusion_matrix(y_test, predict > 0.5))\n",
    "print('Precision, Recall, F\\n', classification_report(\n",
    "    y_test, predict > 0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../PipeLines/Classifications/checker_is_discriptor\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../PipeLines/Classifications/checker_is_discriptor\\assets\n"
     ]
    }
   ],
   "source": [
    "model_class.save('../../PipeLines/Classifications/checker_is_discriptor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nlp_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "451f605c58fa7f82d1d484da5a7eef3d214b63567dc0911e0bf409faa3ae9cbb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
