{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mike\\Desktop\\ITS_project\\ITS_project\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers as ppb # pytorch transformers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from json import load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../Data/Events/type_of_events.json', 'r', encoding='utf-8') as js:\n",
    "    events = load(js)\n",
    "with open('../../Data/Datasets/data.json', 'r', encoding='utf-8') as js:\n",
    "    discriptors = load(js)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in discription_of_event:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_disc = {'expession': [], 'is_discr': []}\n",
    "for subject in discriptors.values():\n",
    "    for d in sum(subject.values(), []):\n",
    "        dict_of_disc['expession'].append(d)\n",
    "        dict_of_disc['is_discr'].append(True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expession</th>\n",
       "      <th>is_discr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>основные положения теории истории</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>основные положения методологии истории</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>место истории в системе гуманитарного знания</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>закономерности исторического процесса</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>этапы исторического процесса</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>методикой использования основных численных мет...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>методикой использования основных численных мет...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>методикой использования основных численных мет...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>методикой использования численных методов реше...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>навыками работы со стандартными математическим...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             expession  is_discr\n",
       "0                    основные положения теории истории      True\n",
       "1               основные положения методологии истории      True\n",
       "2         место истории в системе гуманитарного знания      True\n",
       "3                закономерности исторического процесса      True\n",
       "4                         этапы исторического процесса      True\n",
       "..                                                 ...       ...\n",
       "702  методикой использования основных численных мет...      True\n",
       "703  методикой использования основных численных мет...      True\n",
       "704  методикой использования основных численных мет...      True\n",
       "705  методикой использования численных методов реше...      True\n",
       "706  навыками работы со стандартными математическим...      True\n",
       "\n",
       "[707 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dict_of_disc)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 1.01MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 5.01kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 570/570 [00:00<00:00, 91.6kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 440M/440M [00:50<00:00, 8.70MB/s] \n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# model_class, tokenizer_class, pretrained_weights = (\n",
    "#     ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "# Хотите BERT вместо distilBERT? Раскомментируйте следующую строку:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Загрузка предобученной модели/токенизатора\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  1193, 29747, ...,     0,     0,     0],\n",
       "       [  101,  1193, 29747, ...,     0,     0,     0],\n",
       "       [  101,  1191, 15290, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  1191, 15290, ...,     0,     0,     0],\n",
       "       [  101,  1191, 15290, ...,     0,     0,     0],\n",
       "       [  101,  1192, 10260, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized = df['expession'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "padded = [tokenizer.encode(i, add_special_tokens=True) for i in df['expession'].to_list()]\n",
    "ml = len(max(padded, key=len))\n",
    "for i in padded:\n",
    "    for _ in range(ml-len(i)):\n",
    "        i.append(0)\n",
    "\n",
    "padded = np.array(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(padded)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.41903007,  0.66514844,  0.60549873, ..., -0.48144794,\n",
       "         0.37142098, -0.2614745 ],\n",
       "       [-0.38664246,  0.6248358 ,  0.6110348 , ..., -0.43220413,\n",
       "         0.3550335 , -0.26506042],\n",
       "       [-0.40422782,  0.5560879 ,  0.57891154, ..., -0.41285732,\n",
       "         0.38763666, -0.31203648],\n",
       "       ...,\n",
       "       [-0.13475193,  0.6310348 ,  0.35162398, ..., -0.28626424,\n",
       "         0.28229105, -0.12481178],\n",
       "       [-0.12296842,  0.47135338,  0.5591191 , ..., -0.15835932,\n",
       "         0.34259963, -0.18688935],\n",
       "       [-0.34440002,  0.4739834 ,  0.57158476, ..., -0.2617385 ,\n",
       "         0.35737425, -0.2996565 ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = last_hidden_states[0][:,0,:].numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['is_discr']\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(train_features, train_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITS_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
